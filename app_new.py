# filepath: c:\Users\efren\Desktop\modelo_conceptual\modelos_conceptuales\app.py
# Este archivo est√° alineado y documentado seg√∫n la arquitectura conceptual ubicada en:
# C:\Users\efren\Downloads\supermarket_nn_models_entrega\home\ubuntu\supermarket_nn_models\docs\modelos_conceptuales.md

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src import data_loader, eda, modelo_1_regresion, modelo_2_segmentacion, modelo_3_clasificacion, modelo_4_anomalias
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Modelos Conceptuales Supermercado", 
    layout="wide", 
    initial_sidebar_state="expanded",
    page_icon="üõí"
)

# Configurar matplotlib para mejor compatibilidad
plt.style.use('default')
try:
    plt.style.use('seaborn-v0_8-whitegrid')
except:
    plt.style.use('seaborn-whitegrid')  # Fallback para versiones anteriores

# CSS personalizado
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #2c3e50;
        text-align: center;
        margin-bottom: 0.5em;
        padding: 1em 0;
        background: linear-gradient(90deg, #3498db, #2c3e50);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .subtitle {
        font-size: 1.3rem;
        color: #34495e;
        margin-bottom: 0.5em;
    }
    .stButton>button {
        background-color: #3498db;
        color: white;
        font-weight: bold;
        border-radius: 8px;
        border: none;
        padding: 0.5em 1.5em;
        margin: 0.2em;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #217dbb;
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    .stDataFrame, .stTable {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 0.5em;
        border: 1px solid #e9ecef;
    }
    .metric-container {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e9ecef;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo principal
st.markdown('<div class="main-title">üõí Modelos Conceptuales de Redes Neuronales para Supermercados</div>', unsafe_allow_html=True)

# Sidebar para carga de datos
st.sidebar.header("üìä Carga de Datos")
try:
    st.sidebar.image("data/logo_uc.png", width=120)
except Exception:
    st.sidebar.info("üí° Coloca el logo institucional en 'data/logo_uc.png'")

st.sidebar.markdown('<div class="subtitle">Maestr√≠a en Anal√≠tica de Datos<br>Universidad Central</div>', unsafe_allow_html=True)
archivo = st.sidebar.file_uploader("Sube tu archivo de datos (xlsx)", type=["xlsx"])

# Informaci√≥n del proyecto en sidebar
with st.sidebar.expander("‚ÑπÔ∏è Informaci√≥n del Proyecto"):
    st.markdown("""
    **Modelos Implementados:**
    - üéØ Regresi√≥n (MLPRegressor)
    - üë• Segmentaci√≥n (PCA + KMeans)
    - üõçÔ∏è Clasificaci√≥n (MLPClassifier)
    - üîç Detecci√≥n de Anomal√≠as (Isolation Forest)
    
    **Tecnolog√≠as:**
    - Streamlit
    - Scikit-learn
    - Pandas & NumPy
    - Matplotlib & Seaborn
    """)

# Cargar datos
df = None
if archivo:
    try:
        df = data_loader.cargar_datos(archivo)
        st.success("‚úÖ Datos cargados correctamente.")
        st.sidebar.success(f"üìÅ Archivo: {archivo.name}")
        st.sidebar.info(f"üìä Dimensiones: {df.shape[0]} filas √ó {df.shape[1]} columnas")
    except Exception as e:
        st.error(f"‚ùå Error al cargar el archivo: {e}")
else:
    st.info("üì§ Por favor, sube un archivo de datos para comenzar el an√°lisis.")

if df is not None:
    # An√°lisis Exploratorio de Datos
    st.header("üìä An√°lisis Exploratorio de Datos")
    st.markdown('<div class="subtitle">Explora los datos antes de aplicar los modelos</div>', unsafe_allow_html=True)
    
    try:
        eda.analisis_descriptivo(df)
    except Exception as e:
        st.error(f"Error en el an√°lisis exploratorio: {e}")
    
    st.markdown("---")
    
    # Secci√≥n de Modelos
    st.header("ü§ñ Modelos Propuestos")
    st.markdown('<div class="subtitle">Selecciona y ejecuta el modelo de tu inter√©s</div>', unsafe_allow_html=True)
    
    # Explicaci√≥n de los modelos
    with st.expander("üìñ Explicaci√≥n de los Modelos y Conceptos de Redes Neuronales", expanded=False):
        st.markdown("""
        ### üß† **Conceptos de Redes Neuronales Aplicados:**
        
        **üéØ Regresi√≥n (MLPRegressor):**
        - Utiliza un perceptr√≥n multicapa (red neuronal feedforward)
        - Aprende relaciones no lineales complejas
        - Capas ocultas con activaci√≥n ReLU
        - Predice valores continuos (calificaci√≥n del cliente)
        
        **üë• Segmentaci√≥n (PCA + KMeans):**
        - Simula autoencoders mediante PCA para reducci√≥n de dimensionalidad
        - Encuentra representaciones latentes de los datos
        - Identifica patrones ocultos en el comportamiento del cliente
        - Agrupa clientes similares usando clustering
        
        **üõçÔ∏è Clasificaci√≥n (MLPClassifier):**
        - Red neuronal multicapa para clasificaci√≥n multiclase
        - Funci√≥n de activaci√≥n softmax en la capa de salida
        - Aprende l√≠mites de decisi√≥n complejos
        - Predice categor√≠as (l√≠neas de producto)
        
        **üîç Detecci√≥n de Anomal√≠as (Isolation Forest):**
        - Inspirado en redes neuronales de autoencoder para detecci√≥n de outliers
        - Identifica patrones an√≥malos mediante aislamiento
        - √ötil para detectar fraudes o errores en datos
        """)
    
    # Gu√≠as de selecci√≥n de variables
    with st.expander("üìã Gu√≠as de Selecci√≥n de Variables por Modelo", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### üéØ **Regresi√≥n - Predicci√≥n de Rating**
            **Variables recomendadas:**
            - ‚úÖ Variables de transacci√≥n: `Unit price`, `Quantity`, `Total`, `Tax 5%`, `cogs`, `gross income`
            - ‚úÖ Variables demogr√°ficas: `Gender`, `Customer type`
            - ‚úÖ Variables de producto: `Product line`
            - ‚úÖ Variables de ubicaci√≥n: `Branch`, `City`
            - ‚ùå **Excluir**: `Rating` (variable objetivo)
            
            ### üë• **Segmentaci√≥n de Clientes**
            **Variables recomendadas:**
            - ‚úÖ Variables de comportamiento: `Total`, `Quantity`, `Unit price`, `gross income`
            - ‚úÖ Variables demogr√°ficas: `Gender`, `Customer type`
            - ‚ö†Ô∏è **M√≠nimo 2 variables num√©ricas** para an√°lisis efectivo
            """)
        
        with col2:
            st.markdown("""
            ### üõçÔ∏è **Clasificaci√≥n de Productos**
            **Variables recomendadas:**
            - ‚úÖ Variables de contexto: `Total`, `Quantity`, `Unit price`, `Rating`
            - ‚úÖ Variables demogr√°ficas: `Gender`, `Customer type`, `Branch`
            - ‚úÖ Variables temporales: `Date`, `Time` (si disponibles)
            - ‚ùå **Excluir**: `Product line` (variable objetivo)
            
            ### üîç **Detecci√≥n de Anomal√≠as**
            **Variables recomendadas:**
            - ‚úÖ Variables transaccionales: `Total`, `Quantity`, `Unit price`, `Tax 5%`
            - ‚úÖ Variables de tiempo: `Date`, `Time`
            - ‚úÖ Cualquier variable num√©rica con posibles outliers
            - ‚ö†Ô∏è **M√≠nimo 1 variable** requerida
            """)
    
    # Inicializar session state para selecci√≥n de variables
    if 'var_select' not in st.session_state:
        st.session_state.var_select = list(df.columns)
    
    # Selector de variables mejorado
    st.subheader("üîß Configuraci√≥n de Variables")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        variables = st.multiselect(
            "Selecciona las variables para el an√°lisis:",
            options=list(df.columns),
            default=st.session_state.var_select,
            key="var_select_widget",
            help="Selecciona las variables que deseas usar. Consulta las gu√≠as arriba para recomendaciones."
        )
        
        # Actualizar session_state
        if variables != st.session_state.var_select:
            st.session_state.var_select = variables
    
    with col2:
        st.markdown("**‚ö° Configuraci√≥n R√°pida:**")
        
        if st.button("üéØ Para Regresi√≥n", help="Variables √≥ptimas para regresi√≥n"):
            regression_vars = [col for col in df.columns if col not in ['Rating']]
            st.session_state.var_select = regression_vars
            st.rerun()
        
        if st.button("üë• Para Segmentaci√≥n", help="Variables √≥ptimas para segmentaci√≥n"):
            seg_vars = [col for col in df.columns 
                       if col in ['Total', 'Quantity', 'Unit price', 'gross income', 
                                 'Gender', 'Customer type', 'Branch', 'City']]
            if not seg_vars:
                seg_vars = df.select_dtypes(include=['number']).columns.tolist()
            st.session_state.var_select = seg_vars
            st.rerun()
        
        if st.button("üõçÔ∏è Para Clasificaci√≥n", help="Variables √≥ptimas para clasificaci√≥n"):
            class_vars = [col for col in df.columns if col not in ['Product line']]
            st.session_state.var_select = class_vars
            st.rerun()
        
        if st.button("üîç Para Anomal√≠as", help="Variables √≥ptimas para detecci√≥n de anomal√≠as"):
            anomaly_vars = df.select_dtypes(include=['number']).columns.tolist()
            if 'Date' in df.columns:
                anomaly_vars.append('Date')
            if 'Time' in df.columns:
                anomaly_vars.append('Time')
            st.session_state.var_select = anomaly_vars
            st.rerun()
    
    # Usar variables del session state
    variables = st.session_state.var_select
    
    # Informaci√≥n sobre la selecci√≥n actual
    if variables:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Variables Seleccionadas", len(variables))
        with col2:
            numeric_vars = len([v for v in variables if pd.api.types.is_numeric_dtype(df[v])])
            st.metric("Variables Num√©ricas", numeric_vars)
        with col3:
            categorical_vars = len([v for v in variables if not pd.api.types.is_numeric_dtype(df[v])])
            st.metric("Variables Categ√≥ricas", categorical_vars)
        with col4:
            missing_data = df[variables].isnull().sum().sum()
            st.metric("Datos Faltantes", missing_data)
    
    # Funci√≥n para validar variables por modelo
    def validar_variables_modelo(modelo_tipo, variables_seleccionadas, df):
        """Valida si las variables seleccionadas son apropiadas para el modelo"""
        warnings_list = []
        recommendations = []
        
        if modelo_tipo == "regresion":
            if 'Rating' not in df.columns:
                warnings_list.append("‚ùå La variable 'Rating' es necesaria para el modelo de regresi√≥n.")
            
            numeric_vars = [v for v in variables_seleccionadas if pd.api.types.is_numeric_dtype(df[v])]
            if len(numeric_vars) < 1:
                warnings_list.append("‚ö†Ô∏è Se recomienda al menos 1 variable num√©rica para mejor rendimiento.")
            
            if 'Rating' in variables_seleccionadas:
                recommendations.append("üí° 'Rating' se excluir√° autom√°ticamente ya que es la variable objetivo.")
        
        elif modelo_tipo == "segmentacion":
            numeric_vars = [v for v in variables_seleccionadas if pd.api.types.is_numeric_dtype(df[v])]
            if len(numeric_vars) < 2:
                warnings_list.append("‚ùå Se necesitan al menos 2 variables num√©ricas para segmentaci√≥n efectiva.")
            
            if len(variables_seleccionadas) > 15:
                recommendations.append("üí° Muchas variables seleccionadas. El PCA ayudar√° a reducir dimensionalidad.")
        
        elif modelo_tipo == "clasificacion":
            if 'Product line' not in df.columns:
                warnings_list.append("‚ùå La variable 'Product line' es necesaria para el modelo de clasificaci√≥n.")
            
            if 'Product line' in variables_seleccionadas:
                recommendations.append("üí° 'Product line' se excluir√° autom√°ticamente ya que es la variable objetivo.")
        
        elif modelo_tipo == "anomalias":
            numeric_vars = [v for v in variables_seleccionadas if pd.api.types.is_numeric_dtype(df[v])]
            if len(numeric_vars) < 1:
                warnings_list.append("‚ùå Se necesita al menos 1 variable num√©rica para detecci√≥n de anomal√≠as.")
            
            if len(variables_seleccionadas) == 1:
                recommendations.append("üí° Con 1 variable, las anomal√≠as ser√°n unidimensionales. Considera a√±adir m√°s.")
        
        return warnings_list, recommendations
    
    # Selector de modelo
    st.markdown("---")
    st.subheader("üéØ Selecci√≥n de Modelo")
    
    opcion = st.selectbox(
        "Elige el modelo a ejecutar:",
        [
            "üéØ Regresi√≥n: Predicci√≥n de Rating",
            "üë• Segmentaci√≥n de Clientes", 
            "üõçÔ∏è Clasificaci√≥n de Producto",
            "üîç Detecci√≥n de Anomal√≠as"
        ],
        key="modelo_select"
    )
    
    # Validaciones espec√≠ficas por modelo
    modelo_map = {
        "üéØ Regresi√≥n: Predicci√≥n de Rating": "regresion",
        "üë• Segmentaci√≥n de Clientes": "segmentacion",
        "üõçÔ∏è Clasificaci√≥n de Producto": "clasificacion",
        "üîç Detecci√≥n de Anomal√≠as": "anomalias"
    }
    
    modelo_tipo = modelo_map.get(opcion, "")
    if modelo_tipo:
        warnings_list, recommendations = validar_variables_modelo(modelo_tipo, variables, df)
        
        # Mostrar validaciones
        if warnings_list:
            for warning in warnings_list:
                st.warning(warning)
        
        if recommendations:
            with st.expander("üí° Recomendaciones para optimizar el modelo", expanded=False):
                for rec in recommendations:
                    st.info(rec)
    
    st.markdown("---")
    
    # === IMPLEMENTACI√ìN DE MODELOS ===
    
    if opcion == "üéØ Regresi√≥n: Predicci√≥n de Rating":
        st.subheader("üéØ Modelo de Regresi√≥n (MLPRegressor)")
        
        st.markdown("""
        **Objetivo:** Predecir la calificaci√≥n del cliente bas√°ndose en variables transaccionales y demogr√°ficas.
        
        **Algoritmo:** Red neuronal multicapa que aprende relaciones no lineales complejas entre las variables de entrada y la calificaci√≥n del cliente.
        """)
        
        can_train = 'Rating' in df.columns and len([v for v in variables if pd.api.types.is_numeric_dtype(df[v])]) >= 1
        
        if can_train:
            col1, col2 = st.columns([3, 1])
            
            with col2:
                st.markdown("**‚öôÔ∏è Configuraci√≥n del Modelo:**")
                capas_ocultas = st.selectbox(
                    "Arquitectura de capas ocultas:",
                    [(100,), (128, 64), (128, 64, 32), (100, 50, 25)],
                    index=2,
                    format_func=lambda x: f"{len(x)} capas: {x}"
                )
                
                max_iter = st.slider("M√°ximo de iteraciones:", 200, 1000, 500, 100)
                
            with col1:
                if st.button("üöÄ Entrenar Modelo de Regresi√≥n", type="primary", use_container_width=True):
                    with st.spinner("üîÑ Entrenando modelo de regresi√≥n..."):
                        try:
                            input_vars = [v for v in variables if v != 'Rating']
                            modelo, preproc, resultados = modelo_1_regresion.entrenar_regresion(
                                df[input_vars + ['Rating']].dropna()
                            )
                            
                            st.success("‚úÖ Entrenamiento completado exitosamente!")
                            
                            # M√©tricas principales
                            st.subheader("üìä M√©tricas del Modelo")
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric(
                                    "MSE (Error Cuadr√°tico Medio)", 
                                    f"{resultados['MSE']:.4f}",
                                    help="Menor es mejor"
                                )
                            with col2:
                                st.metric(
                                    "MAE (Error Absoluto Medio)", 
                                    f"{resultados['MAE']:.4f}",
                                    help="Menor es mejor"
                                )
                            with col3:
                                r2_score = resultados['R2']
                                st.metric(
                                    "R¬≤ (Coeficiente de Determinaci√≥n)", 
                                    f"{r2_score:.4f}",
                                    delta=f"{(r2_score - 0.5):.4f}" if r2_score > 0.5 else None,
                                    help="M√°s cercano a 1 es mejor"
                                )
                            
                            # Interpretaci√≥n del modelo
                            st.subheader("üîç Interpretaci√≥n del Modelo")
                            
                            if r2_score > 0.8:
                                st.success("üéâ Excelente rendimiento del modelo (R¬≤ > 0.8)")
                            elif r2_score > 0.6:
                                st.info("üëç Buen rendimiento del modelo (R¬≤ > 0.6)")
                            elif r2_score > 0.4:
                                st.warning("‚ö†Ô∏è Rendimiento moderado del modelo (R¬≤ > 0.4)")
                            else:
                                st.error("‚ùå Rendimiento bajo del modelo (R¬≤ ‚â§ 0.4)")
                            
                            # Visualizaciones
                            st.subheader("üìà An√°lisis Visual")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                # Gr√°fico de predicciones vs reales
                                fig_scatter, ax_scatter = plt.subplots(figsize=(8, 6))
                                
                                sns.scatterplot(
                                    x=resultados['y_test'], 
                                    y=resultados['y_pred'], 
                                    ax=ax_scatter, 
                                    alpha=0.7, 
                                    color='#3498db'
                                )
                                
                                # L√≠nea de predicci√≥n perfecta
                                min_val = min(min(resultados['y_test']), min(resultados['y_pred']))
                                max_val = max(max(resultados['y_test']), max(resultados['y_pred']))
                                ax_scatter.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Predicci√≥n Perfecta')
                                
                                ax_scatter.set_xlabel("Valores Reales", fontsize=12)
                                ax_scatter.set_ylabel("Valores Predichos", fontsize=12)
                                ax_scatter.set_title("Predicciones vs Valores Reales", fontsize=14, fontweight='bold')
                                ax_scatter.legend()
                                ax_scatter.grid(True, alpha=0.3)
                                plt.tight_layout()
                                st.pyplot(fig_scatter)
                            
                            with col2:
                                # An√°lisis de residuos
                                residuos = resultados['y_test'].values - resultados['y_pred']
                                
                                fig_res, ax_res = plt.subplots(figsize=(8, 6))
                                sns.scatterplot(x=resultados['y_pred'], y=residuos, ax=ax_res, alpha=0.7, color='#e74c3c')
                                ax_res.hlines(y=0, xmin=min(resultados['y_pred']), xmax=max(resultados['y_pred']), 
                                            color='black', linestyle='--', linewidth=2)
                                ax_res.set_xlabel("Valores Predichos", fontsize=12)
                                ax_res.set_ylabel("Residuos", fontsize=12)
                                ax_res.set_title("An√°lisis de Residuos", fontsize=14, fontweight='bold')
                                ax_res.grid(True, alpha=0.3)
                                plt.tight_layout()
                                st.pyplot(fig_res)
                            
                            # Distribuci√≥n de residuos
                            st.subheader("üìä Distribuci√≥n de Residuos")
                            fig_hist, ax_hist = plt.subplots(figsize=(10, 6))
                            sns.histplot(residuos, kde=True, ax=ax_hist, color='#9b59b6', alpha=0.7, bins=30)
                            ax_hist.axvline(x=0, color='black', linestyle='--', linewidth=2)
                            ax_hist.set_xlabel("Residuos", fontsize=12)
                            ax_hist.set_ylabel("Frecuencia", fontsize=12)
                            ax_hist.set_title("Distribuci√≥n de Residuos", fontsize=14, fontweight='bold')
                            ax_hist.grid(True, alpha=0.3)
                            plt.tight_layout()
                            st.pyplot(fig_hist)
                            
                            # Estad√≠sticas de residuos
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Media de Residuos", f"{np.mean(residuos):.4f}")
                            with col2:
                                st.metric("Desv. Est√°ndar", f"{np.std(residuos):.4f}")
                            with col3:
                                st.metric("Residuo M√≠nimo", f"{np.min(residuos):.4f}")
                            with col4:
                                st.metric("Residuo M√°ximo", f"{np.max(residuos):.4f}")
                                
                        except Exception as e:
                            st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
                            st.exception(e)
        else:
            st.info("‚ö†Ô∏è Verifica que las variables seleccionadas cumplan con los requisitos.")
    
    elif opcion == "üë• Segmentaci√≥n de Clientes":
        st.subheader("üë• Segmentaci√≥n de Clientes (PCA + KMeans)")
        
        st.markdown("""
        **Objetivo:** Agrupar clientes en segmentos homog√©neos bas√°ndose en patrones de comportamiento.
        
        **Algoritmo:** Reducci√≥n de dimensionalidad con PCA seguida de clustering con KMeans para identificar grupos naturales.
        """)
        
        numeric_vars = [v for v in variables if pd.api.types.is_numeric_dtype(df[v])]
        can_segment = len(numeric_vars) >= 2
        
        if can_segment:
            col1, col2 = st.columns([3, 1])
            
            with col2:
                st.markdown("**‚öôÔ∏è Configuraci√≥n:**")
                n_clusters = st.slider("N√∫mero de segmentos:", min_value=2, max_value=8, value=3)
                
            with col1:
                st.info(f"üí° Se usar√°n {len(numeric_vars)} variables num√©ricas para la segmentaci√≥n")
            
            if st.button("üöÄ Ejecutar Segmentaci√≥n", type="primary", use_container_width=True):
                with st.spinner("üîÑ Segmentando clientes..."):
                    try:
                        df_seg, kmeans, pca, preproc = modelo_2_segmentacion.segmentar_clientes(
                            df[variables].dropna(), 
                            n_clusters=n_clusters
                        )
                        caracteristicas = modelo_2_segmentacion.caracterizar_segmentos(df_seg)
                        
                        st.success("‚úÖ Segmentaci√≥n completada exitosamente!")
                        
                        # M√©tricas de segmentaci√≥n
                        st.subheader("üìä M√©tricas de Segmentaci√≥n")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Segmentos Creados", n_clusters)
                        with col2:
                            st.metric("Clientes Segmentados", len(df_seg))
                        with col3:
                            try:
                                from sklearn.metrics import silhouette_score
                                sil_score = silhouette_score(
                                    pca.transform(preproc.transform(df[variables].dropna())), 
                                    df_seg['Segmento']
                                )
                                st.metric("Silhouette Score", f"{sil_score:.3f}")
                            except:
                                st.metric("Variables Usadas", len(variables))
                        with col4:
                            varianza_explicada = sum(pca.explained_variance_ratio_[:2]) * 100
                            st.metric("Varianza Explicada (PC1+PC2)", f"{varianza_explicada:.1f}%")
                        
                        # Visualizaci√≥n PCA
                        st.subheader("üéØ Visualizaci√≥n de Segmentos (Espacio PCA)")
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            fig, ax = plt.subplots(figsize=(10, 8))
                            pca_coords = pca.transform(preproc.transform(df[variables].dropna()))
                            
                            scatter = sns.scatterplot(
                                x=pca_coords[:,0], 
                                y=pca_coords[:,1], 
                                hue=df_seg['Segmento'], 
                                palette='Set2', 
                                ax=ax,
                                s=100,
                                alpha=0.7
                            )
                            
                            # A√±adir centroides
                            for segment in df_seg['Segmento'].unique():
                                mask = df_seg['Segmento'] == segment
                                centroid_x = pca_coords[mask, 0].mean()
                                centroid_y = pca_coords[mask, 1].mean()
                                ax.scatter(centroid_x, centroid_y, c='black', s=300, marker='X', 
                                         linewidths=3, label=f'Centroide {segment}' if segment == df_seg['Segmento'].unique()[0] else "")
                            
                            ax.set_xlabel(f"PC1 ({pca.explained_variance_ratio_[0]:.1%} varianza)", fontsize=12)
                            ax.set_ylabel(f"PC2 ({pca.explained_variance_ratio_[1]:.1%} varianza)", fontsize=12)
                            ax.set_title("Segmentaci√≥n de Clientes (Espacio PCA)", fontsize=14, fontweight='bold')
                            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                            ax.grid(True, alpha=0.3)
                            plt.tight_layout()
                            st.pyplot(fig)
                        
                        with col2:
                            st.markdown("**üìä Distribuci√≥n de Segmentos:**")
                            segment_counts = df_seg['Segmento'].value_counts().sort_index()
                            
                            for segment, count in segment_counts.items():
                                percentage = (count / len(df_seg)) * 100
                                st.markdown(f"""
                                <div class="metric-container">
                                    <strong>Segmento {segment}:</strong><br>
                                    {count} clientes ({percentage:.1f}%)
                                </div>
                                """, unsafe_allow_html=True)
                        
                        # Caracter√≠sticas por segmento
                        st.subheader("üìã Caracter√≠sticas por Segmento")
                        st.dataframe(caracteristicas.round(3), use_container_width=True)
                        
                        # An√°lisis detallado por variables
                        st.subheader("üìà An√°lisis Detallado por Variables")
                        
                        numeric_vars_for_analysis = [col for col in variables if pd.api.types.is_numeric_dtype(df[col])]
                        
                        if numeric_vars_for_analysis:
                            selected_vars_analysis = st.multiselect(
                                "Selecciona variables para an√°lisis detallado:",
                                options=numeric_vars_for_analysis,
                                default=numeric_vars_for_analysis[:min(len(numeric_vars_for_analysis), 3)],
                                key="segment_analysis_vars"
                            )
                            
                            if selected_vars_analysis:
                                cols_per_row = 2
                                for i in range(0, len(selected_vars_analysis), cols_per_row):
                                    cols = st.columns(cols_per_row)
                                    
                                    for j, var_name in enumerate(selected_vars_analysis[i:i+cols_per_row]):
                                        with cols[j]:
                                            fig_box, ax_box = plt.subplots(figsize=(8, 6))
                                            
                                            sns.boxplot(
                                                data=df_seg, 
                                                x='Segmento', 
                                                y=var_name, 
                                                ax=ax_box, 
                                                palette='Set2'
                                            )
                                            sns.stripplot(
                                                data=df_seg, 
                                                x='Segmento', 
                                                y=var_name, 
                                                ax=ax_box, 
                                                color='black', 
                                                alpha=0.3, 
                                                size=3
                                            )
                                            
                                            ax_box.set_title(f"Distribuci√≥n de {var_name}", fontsize=12, fontweight='bold')
                                            ax_box.grid(True, alpha=0.3)
                                            plt.tight_layout()
                                            st.pyplot(fig_box)
                                
                                # Estad√≠sticas detalladas
                                with st.expander("üìä Estad√≠sticas Detalladas", expanded=False):
                                    for var in selected_vars_analysis:
                                        st.markdown(f"**{var}:**")
                                        stats_by_segment = df_seg.groupby('Segmento')[var].agg([
                                            'count', 'mean', 'std', 'min', 'median', 'max'
                                        ]).round(3)
                                        st.dataframe(stats_by_segment, use_container_width=True)
                        
                        # Opci√≥n de descarga
                        st.subheader("üíæ Descargar Resultados")
                        csv_data = df_seg.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="üì• Descargar datos segmentados (CSV)",
                            data=csv_data,
                            file_name=f"clientes_segmentados_{n_clusters}_grupos.csv",
                            mime="text/csv",
                            help="Descarga el dataset con la asignaci√≥n de segmentos"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå Error durante la segmentaci√≥n: {str(e)}")
                        st.exception(e)
        else:
            st.info("‚ö†Ô∏è Se necesitan al menos 2 variables num√©ricas para la segmentaci√≥n.")
    
    elif opcion == "üõçÔ∏è Clasificaci√≥n de Producto":
        st.subheader("üõçÔ∏è Clasificaci√≥n de Producto (MLPClassifier)")
        
        st.markdown("""
        **Objetivo:** Predecir la l√≠nea de producto bas√°ndose en caracter√≠sticas del cliente y transacci√≥n.
        
        **Algoritmo:** Red neuronal multicapa con clasificaci√≥n multiclase que aprende patrones de compra complejos.
        """)
        
        can_classify = 'Product line' in df.columns
        
        if can_classify:
            product_lines = df['Product line'].unique()
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"üí° Se entrenar√° para clasificar entre {len(product_lines)} l√≠neas de producto")
                
                with st.expander("üìä Distribuci√≥n de L√≠neas de Producto", expanded=False):
                    class_dist = df['Product line'].value_counts()
                    
                    # Gr√°fico de barras
                    fig_dist, ax_dist = plt.subplots(figsize=(10, 6))
                    class_dist.plot(kind='bar', ax=ax_dist, color='skyblue', alpha=0.8)
                    ax_dist.set_title("Distribuci√≥n de L√≠neas de Producto", fontsize=14, fontweight='bold')
                    ax_dist.set_xlabel("L√≠nea de Producto", fontsize=12)
                    ax_dist.set_ylabel("Cantidad", fontsize=12)
                    ax_dist.tick_params(axis='x', rotation=45)
                    ax_dist.grid(True, alpha=0.3)
                    plt.tight_layout()
                    st.pyplot(fig_dist)
                    
                    st.dataframe(
                        class_dist.reset_index().rename(columns={'index': 'L√≠nea de Producto', 'Product line': 'Cantidad'}),
                        use_container_width=True
                    )
            
            with col2:
                st.markdown("**‚öôÔ∏è Configuraci√≥n:**")
                st.metric("Clases √önicas", len(product_lines))
                
                capas_ocultas_clf = st.selectbox(
                    "Arquitectura de capas:",
                    [(100,), (128, 64), (128, 64, 32)],
                    index=1,
                    format_func=lambda x: f"{len(x)} capas: {x}",
                    key="clf_layers"
                )
            
            if st.button("üöÄ Entrenar Modelo de Clasificaci√≥n", type="primary", use_container_width=True):
                with st.spinner("üîÑ Entrenando modelo de clasificaci√≥n..."):
                    try:
                        input_vars = [v for v in variables if v != 'Product line']
                        modelo, preproc, resultados = modelo_3_clasificacion.entrenar_clasificacion(
                            df[input_vars + ['Product line']].dropna()
                        )
                        
                        st.success("‚úÖ Entrenamiento completado exitosamente!")
                        
                        # M√©tricas principales
                        st.subheader("üìä M√©tricas del Modelo")
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Exactitud (Accuracy)", f"{resultados['accuracy']:.3f}")
                        
                        with col2:
                            precision_scores = [v['precision'] for v in resultados['reporte'].values() 
                                              if isinstance(v, dict) and 'precision' in v]
                            if precision_scores:
                                precision_avg = np.mean(precision_scores)
                                st.metric("Precisi√≥n Promedio", f"{precision_avg:.3f}")
                        
                        with col3:
                            recall_scores = [v['recall'] for v in resultados['reporte'].values() 
                                           if isinstance(v, dict) and 'recall' in v]
                            if recall_scores:
                                recall_avg = np.mean(recall_scores)
                                st.metric("Recall Promedio", f"{recall_avg:.3f}")
                        
                        # Matriz de confusi√≥n
                        st.subheader("üìã Matriz de Confusi√≥n")
                        
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            fig, ax = plt.subplots(figsize=(10, 8))
                            
                            sns.heatmap(
                                resultados['matriz_confusion'], 
                                annot=True, 
                                fmt='d', 
                                cmap='Blues', 
                                ax=ax,
                                xticklabels=product_lines,
                                yticklabels=product_lines,
                                cbar_kws={'label': 'Cantidad'}
                            )
                            
                            ax.set_xlabel('Predicci√≥n', fontsize=12)
                            ax.set_ylabel('Real', fontsize=12)
                            ax.set_title('Matriz de Confusi√≥n', fontsize=14, fontweight='bold')
                            plt.xticks(rotation=45)
                            plt.yticks(rotation=0)
                            plt.tight_layout()
                            st.pyplot(fig)
                        
                        with col2:
                            st.markdown("**üìà M√©tricas por Clase:**")
                            reporte_df = pd.DataFrame(resultados['reporte']).transpose()
                            class_metrics = reporte_df.drop(['accuracy', 'macro avg', 'weighted avg'], errors='ignore')
                            st.dataframe(class_metrics.round(3), use_container_width=True)
                        
                        # Interpretaci√≥n del modelo
                        st.subheader("üîç Interpretaci√≥n del Modelo")
                        accuracy = resultados['accuracy']
                        
                        if accuracy > 0.9:
                            st.success("üéâ Excelente rendimiento del modelo (Accuracy > 90%)")
                        elif accuracy > 0.8:
                            st.info("üëç Buen rendimiento del modelo (Accuracy > 80%)")
                        elif accuracy > 0.7:
                            st.warning("‚ö†Ô∏è Rendimiento moderado del modelo (Accuracy > 70%)")
                        else:
                            st.error("‚ùå Rendimiento bajo del modelo (Accuracy ‚â§ 70%)")
                        
                        # An√°lisis de clases m√°s dif√≠ciles de predecir
                        diag = np.diag(resultados['matriz_confusion'])
                        totales_por_clase = resultados['matriz_confusion'].sum(axis=1)
                        accuracy_por_clase = diag / totales_por_clase
                        
                        st.markdown("**üéØ An√°lisis por Clase:**")
                        for i, product_line in enumerate(product_lines):
                            acc_clase = accuracy_por_clase[i]
                            if acc_clase < 0.7:
                                st.warning(f"‚ö†Ô∏è {product_line}: {acc_clase:.2%} - Clase dif√≠cil de predecir")
                            elif acc_clase > 0.9:
                                st.success(f"‚úÖ {product_line}: {acc_clase:.2%} - Excelente predicci√≥n")
                            else:
                                st.info(f"‚ÑπÔ∏è {product_line}: {acc_clase:.2%} - Buena predicci√≥n")
                                
                    except Exception as e:
                        st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")
                        st.exception(e)
        else:
            st.info("‚ö†Ô∏è La variable 'Product line' es necesaria para este modelo.")
    
    elif opcion == "üîç Detecci√≥n de Anomal√≠as":
        st.subheader("üîç Detecci√≥n de Anomal√≠as (Isolation Forest)")
        
        st.markdown("""
        **Objetivo:** Identificar observaciones at√≠picas o an√≥malas en los datos del supermercado.
        
        **Algoritmo:** Isolation Forest a√≠sla anomal√≠as mediante divisiones aleatorias. Las observaciones que requieren menos divisiones para ser aisladas se consideran an√≥malas.
        
        **Aplicaciones:** Detecci√≥n de fraudes, errores de captura, comportamientos inusuales de compra.
        """)
        
        numeric_vars = [v for v in variables if pd.api.types.is_numeric_dtype(df[v])]
        can_detect = len(variables) >= 1
        
        if can_detect:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"üí° Se usar√°n {len(variables)} variables, {len(numeric_vars)} de ellas num√©ricas")
            
            with col2:
                st.markdown("**‚öôÔ∏è Configuraci√≥n:**")
                contamination = st.slider(
                    "Proporci√≥n esperada de anomal√≠as:", 
                    min_value=0.01, 
                    max_value=0.2, 
                    value=0.05, 
                    step=0.01,
                    help="Porcentaje esperado de datos an√≥malos"
                )
                
                n_estimators = st.slider(
                    "N√∫mero de √°rboles:",
                    min_value=50,
                    max_value=200,
                    value=100,
                    step=25
                )
            
            if st.button("üöÄ Detectar Anomal√≠as", type="primary", use_container_width=True):
                with st.spinner("üîÑ Detectando anomal√≠as..."):
                    try:
                        df_anom, modelo, preproc = modelo_4_anomalias.detectar_anomalias(
                            df[variables].dropna(), 
                            variables, 
                            contamination
                        )
                        
                        st.success("‚úÖ Detecci√≥n de anomal√≠as completada!")
                        
                        # M√©tricas principales
                        total_anomalias = sum(df_anom['Anomal√≠a'] == 'S√≠')
                        total_normales = sum(df_anom['Anomal√≠a'] == 'No')
                        
                        st.subheader("üìä Resultados de la Detecci√≥n")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Total Registros", len(df_anom))
                        with col2:
                            st.metric("Anomal√≠as Detectadas", total_anomalias)
                        with col3:
                            st.metric("Datos Normales", total_normales)
                        with col4:
                            percentage = (total_anomalias / len(df_anom)) * 100
                            st.metric("% Anomal√≠as", f"{percentage:.2f}%")
                        
                        # Vista previa de resultados
                        st.subheader("üëÄ Vista Previa de Resultados")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**üìä Datos Normales (muestra):**")
                            normales = df_anom[df_anom['Anomal√≠a'] == 'No'].head()
                            if len(normales) > 0:
                                st.dataframe(normales, use_container_width=True)
                            else:
                                st.info("No hay datos normales para mostrar.")
                        
                        with col2:
                            st.markdown("**üö® Anomal√≠as Detectadas:**")
                            anomalias = df_anom[df_anom['Anomal√≠a'] == 'S√≠']
                            if len(anomalias) > 0:
                                st.dataframe(anomalias, use_container_width=True)
                            else:
                                st.info("No se detectaron anomal√≠as con los par√°metros actuales.")
                        
                        # Distribuci√≥n de anomal√≠as
                        st.subheader("üìä Distribuci√≥n de Anomal√≠as")
                        
                        anomaly_dist = df_anom['Anomal√≠a'].value_counts()
                        
                        fig_dist, ax_dist = plt.subplots(figsize=(8, 6))
                        colors = ['#2ecc71', '#e74c3c']  # Verde para normal, rojo para anomal√≠as
                        bars = ax_dist.bar(anomaly_dist.index, anomaly_dist.values, color=colors, alpha=0.8)
                        
                        # A√±adir etiquetas
                        for bar, value in zip(bars, anomaly_dist.values):
                            height = bar.get_height()
                            ax_dist.text(
                                bar.get_x() + bar.get_width()/2., 
                                height + height*0.01,
                                f'{value}\n({value/len(df_anom)*100:.1f}%)', 
                                ha='center', 
                                va='bottom', 
                                fontweight='bold'
                            )
                        
                        ax_dist.set_title('Distribuci√≥n: Datos Normales vs Anomal√≠as', fontsize=14, fontweight='bold')
                        ax_dist.set_xlabel('Tipo de Dato', fontsize=12)
                        ax_dist.set_ylabel('Cantidad', fontsize=12)
                        ax_dist.grid(True, alpha=0.3)
                        plt.tight_layout()
                        st.pyplot(fig_dist)
                        
                        # An√°lisis visual detallado
                        if numeric_vars:
                            st.subheader("üéØ An√°lisis Visual Detallado")
                            
                            numeric_cols_for_viz = [col for col in df_anom.columns 
                                                   if col != 'Anomal√≠a' and pd.api.types.is_numeric_dtype(df_anom[col])]
                            
                            if numeric_cols_for_viz:
                                selected_viz_vars = st.multiselect(
                                    "Selecciona hasta 2 variables num√©ricas para an√°lisis visual:",
                                    options=numeric_cols_for_viz,
                                    default=numeric_cols_for_viz[:min(len(numeric_cols_for_viz), 2)],
                                    max_selections=2,
                                    key="viz_anomaly_vars"
                                )
                                
                                if selected_viz_vars:
                                    if len(selected_viz_vars) == 1:
                                        var_name = selected_viz_vars[0]
                                        st.markdown(f"**An√°lisis de '{var_name}':**")
                                        
                                        col1, col2 = st.columns(2)
                                        
                                        with col1:
                                            # Histograma
                                            fig_hist, ax_hist = plt.subplots(figsize=(10, 6))
                                            sns.histplot(
                                                data=df_anom, 
                                                x=var_name, 
                                                hue='Anomal√≠a', 
                                                kde=True, 
                                                ax=ax_hist, 
                                                palette={'No':'#5dade2', 'S√≠':'#e74c3c'},
                                                alpha=0.7
                                            )
                                            ax_hist.set_title(f"Distribuci√≥n de {var_name}", fontsize=14, fontweight='bold')
                                            ax_hist.grid(True, alpha=0.3)
                                            plt.tight_layout()
                                            st.pyplot(fig_hist)
                                        
                                        with col2:
                                            # Boxplot
                                            fig_box, ax_box = plt.subplots(figsize=(10, 6))
                                            sns.boxplot(
                                                data=df_anom, 
                                                x='Anomal√≠a', 
                                                y=var_name, 
                                                ax=ax_box, 
                                                palette={'No':'#5dade2', 'S√≠':'#e74c3c'}
                                            )
                                            ax_box.set_title(f"Boxplot de {var_name}", fontsize=14, fontweight='bold')
                                            ax_box.grid(True, alpha=0.3)
                                            plt.tight_layout()
                                            st.pyplot(fig_box)
                                    
                                    elif len(selected_viz_vars) == 2:
                                        var1, var2 = selected_viz_vars[0], selected_viz_vars[1]
                                        st.markdown(f"**Relaci√≥n entre '{var1}' y '{var2}':**")
                                        
                                        fig_scatter, ax_scatter = plt.subplots(figsize=(10, 6))
                                        sns.scatterplot(
                                            data=df_anom, 
                                            x=var1, 
                                            y=var2, 
                                            hue='Anomal√≠a', 
                                            style='Anomal√≠a', 
                                            ax=ax_scatter, 
                                            palette={'No':'#5dade2', 'S√≠':'#e74c3c'}, 
                                            markers={'No':'o', 'S√≠':'X'}, 
                                            s=100,
                                            alpha=0.7
                                        )
                                        ax_scatter.set_title(f"Relaci√≥n entre {var1} y {var2}", fontsize=14, fontweight='bold')
                                        ax_scatter.grid(True, alpha=0.3)
                                        plt.tight_layout()
                                        st.pyplot(fig_scatter)
                                    
                                    # Estad√≠sticas descriptivas
                                    st.subheader("üìà Estad√≠sticas Descriptivas")
                                    
                                    stats_normales = df_anom[df_anom['Anomal√≠a'] == 'No'][selected_viz_vars].describe()
                                    stats_anomalias = df_anom[df_anom['Anomal√≠a'] == 'S√≠'][selected_viz_vars].describe()
                                    
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        st.markdown("**üìä Datos Normales:**")
                                        st.dataframe(stats_normales.round(3), use_container_width=True)
                                    
                                    with col2:
                                        st.markdown("**üö® Anomal√≠as:**")
                                        if len(stats_anomalias.columns) > 0:
                                            st.dataframe(stats_anomalias.round(3), use_container_width=True)
                                        else:
                                            st.info("No hay anomal√≠as suficientes para estad√≠sticas")
                        
                        # Opci√≥n de descarga
                        st.subheader("üíæ Descargar Resultados")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            csv_all = df_anom.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• Descargar todos los datos con etiquetas",
                                data=csv_all,
                                file_name="datos_con_anomalias.csv",
                                mime="text/csv",
                                help="Dataset completo con clasificaci√≥n de anomal√≠as"
                            )
                        
                        with col2:
                            if len(anomalias) > 0:
                                csv_anomalies = anomalias.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="üì• Descargar solo anomal√≠as",
                                    data=csv_anomalies,
                                    file_name="solo_anomalias.csv",
                                    mime="text/csv",
                                    help="Solo los registros identificados como an√≥malos"
                                )
                            else:
                                st.info("No hay anomal√≠as para descargar")
                                
                    except Exception as e:
                        st.error(f"‚ùå Error durante la detecci√≥n: {str(e)}")
                        st.exception(e)
        else:
            st.info("‚ö†Ô∏è Selecciona al menos una variable para detectar anomal√≠as.")
    
    else:
        st.info("Selecciona un modelo para comenzar el an√°lisis.")

else:
    # Mostrar informaci√≥n cuando no hay datos cargados
    st.markdown("---")
    st.subheader("üöÄ ¬øC√≥mo empezar?")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### üì§ 1. Carga tus datos
        - Usa el panel lateral
        - Formato: archivo Excel (.xlsx)
        - Datos de supermercado recomendados
        """)
    
    with col2:
        st.markdown("""
        ### üîß 2. Configura variables
        - Selecciona variables relevantes
        - Usa las gu√≠as de configuraci√≥n r√°pida
        - Revisa las recomendaciones por modelo
        """)
    
    with col3:
        st.markdown("""
        ### ü§ñ 3. Ejecuta modelos
        - Elige el modelo de tu inter√©s
        - Ajusta par√°metros si es necesario
        - Analiza los resultados
        """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #7f8c8d; font-size: 0.9em; margin-top: 2em;'>
    <p><strong>üõí Modelos Conceptuales de Redes Neuronales para Supermercados</strong></p>
    <p>Maestr√≠a en Anal√≠tica de Datos - Universidad Central</p>
    <p>Desarrollado con ‚ù§Ô∏è usando Streamlit, Scikit-learn, y conceptos de Deep Learning</p>
    <p><em>Versi√≥n 3.0 - Noviembre 2024 | Arquitectura completa optimizada</em></p>
</div>
""", unsafe_allow_html=True)
